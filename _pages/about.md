---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
# 👨‍🎓 Biography
Hi! I am Shenghao Xie, a first-year Ph.D. student from [Insight Lab](https://www.maleilab.cn/fulllist), Academy for Advanced Interdisciplinary Studies, Peking University, working with [Prof. Lei Ma](https://www.maleilab.cn/pi) and [Prof. Tiejun Huang](https://idm.pku.edu.cn/info/1017/1040.htm). I also study at [TSAIL Group](https://ml.cs.tsinghua.edu.cn/), Department of Computer Science and Technology, Tsinghua University, advised by [Prof. Hang Su](https://www.suhangss.me/) and [Prof. Jun Zhu](https://ml.cs.tsinghua.edu.cn/~jun/index.shtml). Previously, I received my B.E. degree from School of Cyber Science and Engineering, Wuhan University in 2024, and spent a wonderful time at [HMI Lab](https://pku-hmi-lab.github.io/HMI-Web/), School of Computer Science, Peking University, supervised by [Prof. Shanghang Zhang](https://www.shanghangzhang.com/).

My research interests are primarily on **Large Multimodal Models** with applications on **Embodied Intelligence** and **AI for Science**. I am open to both collaborations and discussions, please feel free to reach me out. 

**Email: shxie2020@gmail.com/shenghaoxie@stu.pku.edu.cn**

**Address: St. Key Lab. of Mult. Inf. Proc., School of Computer Science, Peking University, 4th Floor, Founder Building.**


# 🔥 News
- *2025.9*: &nbsp;🎉🎉 Our paper "[*ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding*](https://arxiv.org/pdf/2506.01853)" is accepted by **NeurIPS 2025** as a spotlight paper.  
- *2024.10*: &nbsp;🎉🎉 Our paper "[*Embedded Visual Prompt Tuning*](https://www.sciencedirect.com/science/article/abs/pii/S136184152400183X)" is accepted by **MIA 2024**.  

# 📝 Selected Publications
(__*__ denotes co-first author. __†__ denotes project leader. __☨__ denotes corresponding author. View the full publication list on my google scholar.)
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2025 (Spotlight)</div><img src='images/shapellmomni.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding**

Junliang Ye, Zhengyi Wang, Ruowen Zhao, **Shenghao Xie**, Jun Zhu

[**Paper**](https://arxiv.org/pdf/2506.01853) <strong><span class='show_paper_citations' data='hcrnA7sAAAAJ:2osOgNQ5qMEC'></span></strong>
[**Code**](https://github.com/JAMESYJL/ShapeLLM-Omni/)
- The first large 3D native multimodal model.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MIA 2024</div><img src='images/EPT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Embedded Visual Prompt Tuning**

Wenqiang Zu, **Shenghao Xie***, Qing Zhao, Guoqi Li, Lei Ma

[**Paper**](https://www.sciencedirect.com/science/article/abs/pii/S136184152400183X) <strong><span class='show_paper_citations' data='hcrnA7sAAAAJ:2osOgNQ5qMEC'></span></strong>
[**Code**](https://github.com/zuwenqiang/EPT)
- Embed but not prepend, try to concat prompts with embeddings in channels.
</div>
</div>

# 🎖 Honors and Awards
- *2024.06* Wuhan University Outstanding Bachelor's Degree Thesis.
- *2023.11* Lei Jun Computer Science Undergraduate Scholarship.
- *2023.08* National College Student Information Security Contest First Prize.  

# 💻 Internships
- *2023.09 - 2024.09*, research intern, [Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/), Beijing, China. Mentor: Lei Ma, Tiejun Huang.

# 📕 Services
- Reviewer: AAAI/TMI
- TA: *2025 Spring*, Artificial Intelligence, instructed by Prof. Shanghang Zhang.
